{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b21268a-5c59-4575-a591-afcd0fa11b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nebula.data.yg_ar.setup_data_image_hard import read_data\n",
    "from nebula.common import to_scale_one, write_pickle, read_pickle\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6aa2df-d80c-403c-b0a9-33557679ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_map(labels):\n",
    "    label_set = set()\n",
    "    for lt in labels:\n",
    "        label_set.add(lt)\n",
    "        \n",
    "    label_set = list(label_set)\n",
    "    label_set.sort()\n",
    "\n",
    "    label_map = {}\n",
    "    count = 0\n",
    "    for l in label_set:\n",
    "        label_map[l] = count\n",
    "        count += 1\n",
    "        \n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a61a52-7118-41fe-a695-77ff63c615a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/image_easy2_ds_hog_pca.pkl\"\n",
    "df, train_df, test_df, valid_df = read_pickle(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b999c1-de4d-4244-9acc-7b791049f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_a = create_label_map(df[\"label_a\"])\n",
    "label_map_at = create_label_map(df[\"label_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce63941-c9fc-4c11-9fbf-4947ee998238",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df[\"image\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd5319f-95ee-4a1a-a056-c755af2930bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_a = train_df[\"label_a\"].map(label_map_a).to_list()\n",
    "train_y_at = train_df[\"label_at\"].map(label_map_at).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21f1acf-b2c2-4f1d-87f8-093f2da21874",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_df[\"image\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fefefe69-772d-4d2a-ae8f-88c4f158a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_a = test_df[\"label_a\"].map(label_map_a).to_list()\n",
    "test_y_at = test_df[\"label_at\"].map(label_map_at).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2c2f26-4604-47b8-9ca8-403a0d7e69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(data_x, data_y):\n",
    "    clf = svm.SVC(max_iter=50)\n",
    "    clf.fit(data_x, data_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_logistic(data_x, data_y):\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(data_x, data_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_gbt(data_x, data_y):\n",
    "    clf = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=3,\n",
    "        random_state=0,\n",
    "        verbose=1,\n",
    "        n_iter_no_change=2,\n",
    "    )\n",
    "    clf.fit(data_x, data_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def evaluate(model, test_x, test_y):\n",
    "    res = model.predict(test_x)\n",
    "    correct = res == test_y\n",
    "    accuracy = correct.sum() / len(res)\n",
    "    return res, accuracy\n",
    "\n",
    "\n",
    "def create_dirs_to_file(path):\n",
    "    dirs = \"/\".join(osp.join(path).split(\"/\")[:-1])\n",
    "    if not osp.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "\n",
    "\n",
    "def load_or_train(train_x, train_y, test_x, test_y, train_func, label_map, path):\n",
    "    \n",
    "    if osp.exists(path):\n",
    "        return read_pickle(path)\n",
    "    \n",
    "    create_dirs_to_file(path)\n",
    "    \n",
    "    trained_model = train_func(train_x, train_y)\n",
    "    predictions, accuracy = evaluate(trained_model, test_x, test_y)\n",
    "    \n",
    "    df, df_incorrect, df_correct = format_results(predictions, test_y, label_map)\n",
    "    \n",
    "    write_pickle(path, (trained_model, predictions, accuracy, df, df_incorrect, df_correct, label_map)) \n",
    "    \n",
    "    return trained_model, predictions, accuracy, df, df_incorrect, df_correct, label_map\n",
    "\n",
    "\n",
    "def format_results(predictions, labels, label_map):\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            \"prediction\": predictions,\n",
    "            \"label\": labels\n",
    "        }\n",
    "    )\n",
    "    df[\"check\"] = df[\"prediction\"] == df[\"label\"]\n",
    "\n",
    "    label_map_reverse = {v:k for k, v in label_map.items()}\n",
    "\n",
    "    df[\"prediction_name\"] = df.prediction.map(label_map_reverse)\n",
    "    df[\"label_name\"] = df.label.map(label_map_reverse)\n",
    "\n",
    "    df_incorrect = df[~df.check]\n",
    "    df_correct = df[df.check]\n",
    "\n",
    "    return df, df_incorrect, df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07de2998-8e41-4921-a595-d1096dfa7952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6819444444444445\n",
      "    prediction  label  check    prediction_name   label_name\n",
      "7            3      5  False  lord_of_the_dance  thunderbolt\n",
      "14           0      5  False              camel  thunderbolt\n",
      "28           3      5  False  lord_of_the_dance  thunderbolt\n",
      "40           1      5  False              chair  thunderbolt\n",
      "42           3      5  False  lord_of_the_dance  thunderbolt\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_hog_pca/svm_a.pkl\"\n",
    "(\n",
    "    trained_svm_a, \n",
    "    predictions_svm_a, \n",
    "    accuracy_svm_a, \n",
    "    df_svm_a, \n",
    "    df_incorrect_svm_a, \n",
    "    df_correct_svm_a,\n",
    "    label_map_svm_a\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_a, \n",
    "    test_x, \n",
    "    test_y_a, \n",
    "    train_svm, \n",
    "    label_map_a, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_svm_a)\n",
    "print(df_incorrect_svm_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66359b0a-dfe3-40b8-b97c-d1af8342f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5430555555555555\n",
      "   prediction  label  check prediction_name     label_name\n",
      "3          22     23  False   thunderbolt_3  thunderbolt_4\n",
      "5          22     23  False   thunderbolt_3  thunderbolt_4\n",
      "6          22     23  False   thunderbolt_3  thunderbolt_4\n",
      "7          22     23  False   thunderbolt_3  thunderbolt_4\n",
      "8          22     23  False   thunderbolt_3  thunderbolt_4\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_hog_pca/svm_at.pkl\"\n",
    "(\n",
    "    trained_svm_at, \n",
    "    predictions_svm_at, \n",
    "    accuracy_svm_at, \n",
    "    df_svm_at,\n",
    "    df_incorrect_svm_at, \n",
    "    df_correct_svm_at,\n",
    "    label_map_svm_at\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_at, \n",
    "    test_x, \n",
    "    test_y_at, \n",
    "    train_svm, \n",
    "    label_map_at, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_svm_at)\n",
    "print(df_incorrect_svm_at.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a75f18-62af-48c3-aed8-c9dc7196d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5462962962962963\n",
      "   prediction  label  check    prediction_name   label_name\n",
      "1           0      5  False              camel  thunderbolt\n",
      "5           0      5  False              camel  thunderbolt\n",
      "6           7      5  False         upward_dog  thunderbolt\n",
      "7           3      5  False  lord_of_the_dance  thunderbolt\n",
      "8           0      5  False              camel  thunderbolt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_hog_pca/logistic_a.pkl\"\n",
    "(\n",
    "    trained_logistic_a, \n",
    "    predictions_logistic_a, \n",
    "    accuracy_logistic_a, \n",
    "    df_logistic_a,\n",
    "    df_incorrect_logistic_a, \n",
    "    df_correct_logistic_a,\n",
    "    label_map_logistic_a\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_a, \n",
    "    test_x, \n",
    "    test_y_a, \n",
    "    train_logistic, \n",
    "    label_map_a, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_logistic_a)\n",
    "print(df_incorrect_logistic_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c02bb52-29e4-4650-9336-4a9a406395df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20833333333333334\n",
      "   prediction  label  check prediction_name     label_name\n",
      "1          22     23  False   thunderbolt_3  thunderbolt_4\n",
      "2          22     23  False   thunderbolt_3  thunderbolt_4\n",
      "3          22     23  False   thunderbolt_3  thunderbolt_4\n",
      "4          20     23  False   thunderbolt_1  thunderbolt_4\n",
      "5           3     23  False         camel_4  thunderbolt_4\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_hog_pca/logistic_at.pkl\"\n",
    "(\n",
    "    trained_logistic_at, \n",
    "    predictions_logistic_at, \n",
    "    accuracy_logistic_at, \n",
    "    df_logistic_at,\n",
    "    df_incorrect_logistic_at, \n",
    "    df_correct_logistic_at,\n",
    "    label_map_logistic_at\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_at, \n",
    "    test_x, \n",
    "    test_y_at, \n",
    "    train_logistic, \n",
    "    label_map_at, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_logistic_at)\n",
    "print(df_incorrect_logistic_at.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a42d41d-2ee1-4d85-90eb-1acc3756f7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           2.2849           80.08m\n",
      "         2           2.2680           77.67m\n",
      "         3           2.2517           75.96m\n",
      "         4           2.2361           73.54m\n",
      "         5           2.2212           74.82m\n",
      "         6           2.2066           72.84m\n",
      "         7           2.1929           70.60m\n",
      "         8           2.1795           68.67m\n",
      "         9           2.1664           67.86m\n",
      "        10           2.1538           67.01m\n",
      "        20           2.0428           58.64m\n",
      "        30           1.9512           55.44m\n",
      "        40           1.8707           47.58m\n",
      "        50           1.7983           64.22m\n",
      "        60           1.7346          126.63m\n",
      "        70           1.6774           89.33m\n",
      "        80           1.6260           53.89m\n",
      "        90           1.5791           24.46m\n",
      "       100           1.5357            0.00s\n",
      "0.5722222222222222\n",
      "    prediction  label  check    prediction_name   label_name\n",
      "3            0      5  False              camel  thunderbolt\n",
      "5            0      5  False              camel  thunderbolt\n",
      "16           0      5  False              camel  thunderbolt\n",
      "17           6      5  False           triangle  thunderbolt\n",
      "19           3      5  False  lord_of_the_dance  thunderbolt\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_hog_pca/gbt_a.pkl\"\n",
    "(\n",
    "    trained_gbt_a, \n",
    "    predictions_gbt_a, \n",
    "    accuracy_gbt_a, \n",
    "    df_gbt_a, \n",
    "    df_incorrect_gbt_a, \n",
    "    df_correct_gbt_a,\n",
    "    label_map_gbt_a\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_a, \n",
    "    test_x, \n",
    "    test_y_a, \n",
    "    train_gbt, \n",
    "    label_map_a, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_gbt_a)\n",
    "print(df_incorrect_gbt_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f38dd9-b491-48bb-adff-bd7c0b59b7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           3.6524          191.56m\n",
      "         2           3.6221          188.81m\n",
      "         3           3.5951          181.96m\n",
      "         4           3.5712          183.02m\n",
      "         5           3.5480          178.48m\n",
      "         6           3.5266          175.52m\n",
      "         7           3.5057          172.42m\n",
      "         8           3.4864          169.75m\n",
      "         9           3.4677          167.85m\n",
      "        10           3.4501          166.35m\n",
      "        20           3.2999          153.19m\n",
      "        30           3.1759          135.48m\n",
      "        40           3.0686          137.52m\n",
      "        50           2.9712          121.47m\n",
      "        60           2.8864          100.90m\n",
      "        70           2.8097           73.92m\n",
      "        80           2.7362           49.08m\n",
      "        90           2.6707           24.17m\n",
      "       100           2.6090            0.00s\n",
      "0.2675925925925926\n",
      "   prediction  label  check      prediction_name     label_name\n",
      "1          21     23  False        thunderbolt_2  thunderbolt_4\n",
      "2          21     23  False        thunderbolt_2  thunderbolt_4\n",
      "3          13     23  False  lord_of_the_dance_2  thunderbolt_4\n",
      "4          22     23  False        thunderbolt_3  thunderbolt_4\n",
      "5          20     23  False        thunderbolt_1  thunderbolt_4\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_hog_pca/gbt_at.pkl\"\n",
    "(\n",
    "    trained_gbt_at, \n",
    "    predictions_gbt_at, \n",
    "    accuracy_gbt_at, \n",
    "    df_gbt_at, \n",
    "    df_incorrect_gbt_at, \n",
    "    df_correct_gbt_at,\n",
    "    label_map_gbt_at\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_at, \n",
    "    test_x, \n",
    "    test_y_at, \n",
    "    train_gbt, \n",
    "    label_map_at, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_gbt_at)\n",
    "print(df_incorrect_gbt_at.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ed307-80fc-4e1e-a96f-5209982e8d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
