{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b21268a-5c59-4575-a591-afcd0fa11b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nebula.data.yg_ar.setup_data_image_hard import read_data\n",
    "from nebula.common import to_scale_one, write_pickle, read_pickle\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6aa2df-d80c-403c-b0a9-33557679ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_map(labels):\n",
    "    label_set = set()\n",
    "    for lt in labels:\n",
    "        label_set.add(lt)\n",
    "        \n",
    "    label_set = list(label_set)\n",
    "    label_set.sort()\n",
    "\n",
    "    label_map = {}\n",
    "    count = 0\n",
    "    for l in label_set:\n",
    "        label_map[l] = count\n",
    "        count += 1\n",
    "        \n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a61a52-7118-41fe-a695-77ff63c615a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/image_easy2_ds_pca.pkl\"\n",
    "df, train_df, test_df, valid_df = read_pickle(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b999c1-de4d-4244-9acc-7b791049f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_a = create_label_map(df[\"label_a\"])\n",
    "label_map_at = create_label_map(df[\"label_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce63941-c9fc-4c11-9fbf-4947ee998238",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df[\"image\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd5319f-95ee-4a1a-a056-c755af2930bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_a = train_df[\"label_a\"].map(label_map_a).to_list()\n",
    "train_y_at = train_df[\"label_at\"].map(label_map_at).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21f1acf-b2c2-4f1d-87f8-093f2da21874",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_df[\"image\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fefefe69-772d-4d2a-ae8f-88c4f158a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_a = test_df[\"label_a\"].map(label_map_a).to_list()\n",
    "test_y_at = test_df[\"label_at\"].map(label_map_at).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2c2f26-4604-47b8-9ca8-403a0d7e69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(data_x, data_y):\n",
    "    clf = svm.SVC(max_iter=50)\n",
    "    clf.fit(data_x, data_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_logistic(data_x, data_y):\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(data_x, data_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_gbt(data_x, data_y):\n",
    "    clf = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=3,\n",
    "        random_state=0,\n",
    "        verbose=1,\n",
    "        n_iter_no_change=2,\n",
    "    )\n",
    "    clf.fit(data_x, data_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def evaluate(model, test_x, test_y):\n",
    "    res = model.predict(test_x)\n",
    "    correct = res == test_y\n",
    "    accuracy = correct.sum() / len(res)\n",
    "    return res, accuracy\n",
    "\n",
    "\n",
    "def create_dirs_to_file(path):\n",
    "    dirs = \"/\".join(osp.join(path).split(\"/\")[:-1])\n",
    "    if not osp.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "\n",
    "\n",
    "def load_or_train(train_x, train_y, test_x, test_y, train_func, label_map, path):\n",
    "    \n",
    "    if osp.exists(path):\n",
    "        return read_pickle(path)\n",
    "    \n",
    "    create_dirs_to_file(path)\n",
    "    \n",
    "    trained_model = train_func(train_x, train_y)\n",
    "    predictions, accuracy = evaluate(trained_model, test_x, test_y)\n",
    "    \n",
    "    df, df_incorrect, df_correct = format_results(predictions, test_y, label_map)\n",
    "    \n",
    "    write_pickle(path, (trained_model, predictions, accuracy, df, df_incorrect, df_correct, label_map)) \n",
    "    \n",
    "    return trained_model, predictions, accuracy, df, df_incorrect, df_correct, label_map\n",
    "\n",
    "\n",
    "def format_results(predictions, labels, label_map):\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            \"prediction\": predictions,\n",
    "            \"label\": labels\n",
    "        }\n",
    "    )\n",
    "    df[\"check\"] = df[\"prediction\"] == df[\"label\"]\n",
    "\n",
    "    label_map_reverse = {v:k for k, v in label_map.items()}\n",
    "\n",
    "    df[\"prediction_name\"] = df.prediction.map(label_map_reverse)\n",
    "    df[\"label_name\"] = df.label.map(label_map_reverse)\n",
    "\n",
    "    df_incorrect = df[~df.check]\n",
    "    df_correct = df[df.check]\n",
    "\n",
    "    return df, df_incorrect, df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07de2998-8e41-4921-a595-d1096dfa7952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48333333333333334\n",
      "   prediction  label  check    prediction_name  label_name\n",
      "0           0      8  False              camel  warrior_II\n",
      "1           1      8  False              chair  warrior_II\n",
      "2           3      8  False  lord_of_the_dance  warrior_II\n",
      "4           1      8  False              chair  warrior_II\n",
      "6           3      8  False  lord_of_the_dance  warrior_II\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_pca/svm_a.pkl\"\n",
    "(\n",
    "    trained_svm_a, \n",
    "    predictions_svm_a, \n",
    "    accuracy_svm_a, \n",
    "    df_svm_a, \n",
    "    df_incorrect_svm_a, \n",
    "    df_correct_svm_a,\n",
    "    label_map_svm_a\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_a, \n",
    "    test_x, \n",
    "    test_y_a, \n",
    "    train_svm, \n",
    "    label_map_a, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_svm_a)\n",
    "print(df_incorrect_svm_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66359b0a-dfe3-40b8-b97c-d1af8342f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4199074074074074\n",
      "   prediction  label  check      prediction_name    label_name\n",
      "2          13     37  False  lord_of_the_dance_2  warrior_II_2\n",
      "3          36     37  False         warrior_II_1  warrior_II_2\n",
      "4          36     37  False         warrior_II_1  warrior_II_2\n",
      "5          39     37  False         warrior_II_4  warrior_II_2\n",
      "6          36     37  False         warrior_II_1  warrior_II_2\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_pca/svm_at.pkl\"\n",
    "(\n",
    "    trained_svm_at, \n",
    "    predictions_svm_at, \n",
    "    accuracy_svm_at, \n",
    "    df_svm_at,\n",
    "    df_incorrect_svm_at, \n",
    "    df_correct_svm_at,\n",
    "    label_map_svm_at\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_at, \n",
    "    test_x, \n",
    "    test_y_at, \n",
    "    train_svm, \n",
    "    label_map_at, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_svm_at)\n",
    "print(df_incorrect_svm_at.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a75f18-62af-48c3-aed8-c9dc7196d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44351851851851853\n",
      "   prediction  label  check    prediction_name  label_name\n",
      "2           5      8  False        thunderbolt  warrior_II\n",
      "5           9      8  False        warrior_III  warrior_II\n",
      "6           3      8  False  lord_of_the_dance  warrior_II\n",
      "7           3      8  False  lord_of_the_dance  warrior_II\n",
      "8           1      8  False              chair  warrior_II\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_pca/logistic_a.pkl\"\n",
    "(\n",
    "    trained_logistic_a, \n",
    "    predictions_logistic_a, \n",
    "    accuracy_logistic_a, \n",
    "    df_logistic_a,\n",
    "    df_incorrect_logistic_a, \n",
    "    df_correct_logistic_a,\n",
    "    label_map_logistic_a\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_a, \n",
    "    test_x, \n",
    "    test_y_a, \n",
    "    train_logistic, \n",
    "    label_map_a, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_logistic_a)\n",
    "print(df_incorrect_logistic_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c02bb52-29e4-4650-9336-4a9a406395df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16944444444444445\n",
      "   prediction  label  check prediction_name    label_name\n",
      "0          36     37  False    warrior_II_1  warrior_II_2\n",
      "1          36     37  False    warrior_II_1  warrior_II_2\n",
      "2          21     37  False   thunderbolt_2  warrior_II_2\n",
      "3          38     37  False    warrior_II_3  warrior_II_2\n",
      "4          39     37  False    warrior_II_4  warrior_II_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_pca/logistic_at.pkl\"\n",
    "(\n",
    "    trained_logistic_at, \n",
    "    predictions_logistic_at, \n",
    "    accuracy_logistic_at, \n",
    "    df_logistic_at,\n",
    "    df_incorrect_logistic_at, \n",
    "    df_correct_logistic_at,\n",
    "    label_map_logistic_at\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_at, \n",
    "    test_x, \n",
    "    test_y_at, \n",
    "    train_logistic, \n",
    "    label_map_at, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_logistic_at)\n",
    "print(df_incorrect_logistic_at.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a42d41d-2ee1-4d85-90eb-1acc3756f7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           2.2929           54.43m\n",
      "         2           2.2836           59.06m\n",
      "         3           2.2746           55.04m\n",
      "         4           2.2660           53.68m\n",
      "         5           2.2577           52.49m\n",
      "         6           2.2495           55.07m\n",
      "         7           2.2416           54.41m\n",
      "         8           2.2338           53.26m\n",
      "         9           2.2263           51.79m\n",
      "        10           2.2189           50.60m\n",
      "        20           2.1519           49.80m\n",
      "        30           2.0938           46.60m\n",
      "        40           2.0402           41.09m\n",
      "        50           1.9916           34.64m\n",
      "        60           1.9471           29.20m\n",
      "        70           1.9057           22.21m\n",
      "        80           1.8677           21.34m\n",
      "        90           1.8334           23.38m\n",
      "       100           1.8016            0.00s\n",
      "0.462037037037037\n",
      "   prediction  label  check    prediction_name  label_name\n",
      "0           5      8  False        thunderbolt  warrior_II\n",
      "1           5      8  False        thunderbolt  warrior_II\n",
      "2           3      8  False  lord_of_the_dance  warrior_II\n",
      "3           6      8  False           triangle  warrior_II\n",
      "4           1      8  False              chair  warrior_II\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_pca/gbt_a.pkl\"\n",
    "(\n",
    "    trained_gbt_a, \n",
    "    predictions_gbt_a, \n",
    "    accuracy_gbt_a, \n",
    "    df_gbt_a, \n",
    "    df_incorrect_gbt_a, \n",
    "    df_correct_gbt_a,\n",
    "    label_map_gbt_a\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_a, \n",
    "    test_x, \n",
    "    test_y_a, \n",
    "    train_gbt, \n",
    "    label_map_a, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_gbt_a)\n",
    "print(df_incorrect_gbt_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f38dd9-b491-48bb-adff-bd7c0b59b7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           3.6669          147.14m\n",
      "         2           3.6492          146.56m\n",
      "         3           3.6337          154.40m\n",
      "         4           3.6194          155.92m\n",
      "         5           3.6064          157.70m\n",
      "         6           3.5945          158.72m\n",
      "         7           3.5826          158.31m\n",
      "         8           3.5719          158.01m\n",
      "         9           3.5610          158.35m\n",
      "        10           3.5505          157.51m\n",
      "        20           3.4559          144.21m\n",
      "        30           3.3749          133.33m\n",
      "        40           3.3000          119.73m\n",
      "        50           3.2296          102.98m\n",
      "        60           3.1663           83.80m\n",
      "        70           3.1052           64.11m\n",
      "        80           3.0472           43.54m\n",
      "        90           2.9936           21.79m\n",
      "       100           2.9412            0.00s\n",
      "0.18009259259259258\n",
      "   prediction  label  check prediction_name    label_name\n",
      "0          22     37  False   thunderbolt_3  warrior_II_2\n",
      "2          25     37  False      triangle_2  warrior_II_2\n",
      "3           4     37  False         chair_1  warrior_II_2\n",
      "4           4     37  False         chair_1  warrior_II_2\n",
      "5          36     37  False    warrior_II_1  warrior_II_2\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_pca/gbt_at.pkl\"\n",
    "(\n",
    "    trained_gbt_at, \n",
    "    predictions_gbt_at, \n",
    "    accuracy_gbt_at, \n",
    "    df_gbt_at, \n",
    "    df_incorrect_gbt_at, \n",
    "    df_correct_gbt_at,\n",
    "    label_map_gbt_at\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_at, \n",
    "    test_x, \n",
    "    test_y_at, \n",
    "    train_gbt, \n",
    "    label_map_at, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_gbt_at)\n",
    "print(df_incorrect_gbt_at.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ed307-80fc-4e1e-a96f-5209982e8d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
